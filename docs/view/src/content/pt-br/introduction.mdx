---
title: Introdução
description: Aprenda sobre deco - a fundação open-source para construir software nativo de IA
icon: Rocket
---

**deco é uma fundação open-source para construir software nativo de IA.**

Fornecemos os componentes principais para criar ferramentas, fluxos de trabalho, visualizações personalizadas e sistemas completos alimentados por IA.

Este repositório é para qualquer pessoa que esteja construindo software com foco em IA, desde vibecoders prototipando ideias até engenheiros agentivos enviando sistemas de produção.

Nosso objetivo é ajudar equipes a adotar GenAI dando aos construtores as ferramentas para criar aplicações nativas de IA sustentáveis e governadas que escalam além da demonstração inicial e para milhares de usuários, de forma segura e econômica.

## Capacidades Principais

- **Runtime open-source** que permite compor ferramentas, fluxos de trabalho e visualizações dentro de uma única base de código.
- **MCP Mesh (Model Context Protocol)**: Conecte modelos, armazenamentos de dados e APIs com segurança, observabilidade e controle de custos.
- **Stack TypeScript unificado** — lógica de backend e UIs React/Tailwind personalizadas no mesmo repositório, com vinculações RPC tipadas.
- **Infraestrutura modular** implantada na Cloudflare para execução global de baixa latência. Auto-hospede apenas com sua Cloudflare API Key e escale infinitamente.
- **Espaço de trabalho visual** onde qualquer pessoa pode construir agentes, conectar ferramentas, gerenciar permissões e aproveitar tudo construído em código.

## Conceitos Principais

Antes de mergulhar, vamos definir rapidamente algumas ideias principais no deco:

### Ferramentas

Funções discretas que executam tarefas específicas (ex: chamar uma API, consultar um banco de dados, enviar um email). As ferramentas são definidas por desenvolvedores com esquemas de entrada/saída e executadas via runtime da plataforma.

### Fluxos de Trabalho

Sequências de múltiplas etapas que orquestram Ferramentas e lógica. Os fluxos de trabalho permitem encadear chamadas de ferramentas, aplicar condições, loops e paralelismo para implementar comportamentos complexos. Eles são definidos usando o motor de fluxo de trabalho do Mastra.

### MCP (Model Context Protocol)

O protocolo que sustenta o deco que conecta modelos de IA (como Claude ou GPT) com suas Ferramentas/Fluxos de Trabalho. Um "servidor" MCP é essencialmente seu Cloudflare Worker que expõe Ferramentas e Fluxos de Trabalho para o agente. Isso permite que um agente invoque funções de forma estruturada.

### Agentes

Atores de IA autônomos (apoiados por LLMs) que você configura com um nome, descrição e prompt de comportamento. Os agentes podem conversar em linguagem natural e decidir quando chamar Ferramentas para executar ações.

### Integrações

Conexões pré-construídas ou personalizadas com serviços externos e fontes de dados. As integrações podem incluir APIs de terceiros (como Gmail, Slack), bancos de dados, ou uma **Base de Conhecimento** de documentos. Elas fornecem os blocos de construção (como Ferramentas) que seus agentes e fluxos de trabalho podem aproveitar sem começar do zero.

## Criando um Novo Projeto Deco

Um **projeto Deco** estende um Cloudflare Worker padrão com nossos blocos de construção e padrões projetados para servidores MCP. Ele executa um servidor MCP com uma API type-safe por padrão e também pode servir visualizações — aplicações front-end implantadas junto com o servidor.

Por enquanto, as visualizações podem ser qualquer aplicação Vite que produza uma build estática. Em breve, suportaremos componentes de visualização declarados como ferramentas, tornando-os chamáveis pela lógica do seu aplicativo ou LLMs. As visualizações podem chamar ferramentas do lado do servidor através de RPC type-safe.
